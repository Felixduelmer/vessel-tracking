{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os,sys\n",
    "\n",
    "from modules.UNet import *\n",
    "from modules.DataSet import *\n",
    "from modules.Losses import *\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,device,val_per=0.1,epochs=10,batch_size=10,resize_to=None):\n",
    "    if resize_to is not None:\n",
    "        transform_image = transforms.Compose([\n",
    "        transforms.Resize(resize_to),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(0.5,0.5)\n",
    "        ])\n",
    "        transform_label = transforms.Compose([\n",
    "        transforms.Resize(resize_to),\n",
    "        #transforms.ToTensor()\n",
    "        ])\n",
    "    else:\n",
    "        transform_image = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(0.5,0.5)\n",
    "        ])\n",
    "        transform_label = transforms.Compose([\n",
    "        #transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    dataSet = UltraSoundDataSet2(root_dir,[transform_image,transform_label])\n",
    "    nTrain = int(len(dataSet)*(1-val_per))\n",
    "    nValid = int(len(dataSet)-nTrain)\n",
    "    \n",
    "    trainSet,validSet = random_split(dataSet,[nTrain,nValid])\n",
    "    \n",
    "    train_loader = DataLoader(trainSet,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "    valid_loader = DataLoader(validSet,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',patience=10)\n",
    "    \n",
    "    running_loss_seg = 0\n",
    "    \n",
    "    step = 0\n",
    "    np.set_printoptions(precision=2)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            imgs,labels = batch\n",
    "\n",
    "            images = imgs.to(device=device,dtype=torch.float32)\n",
    "            labels = labels.to(device=device,dtype=torch.float32)\n",
    "            \n",
    "            pred = net(images)\n",
    "                \n",
    "            seg_loss = DiceLoss(pred,labels)\n",
    "            \n",
    "            #print(seg_loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            seg_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss_seg += seg_loss.item()\n",
    "            \n",
    "            step += 1    \n",
    "            if step % 10 == 9:    # print every 10 mini-batches\n",
    "                print()\n",
    "                print('[%d, %5d] loss: %.3f' %(epoch + 1, step + 1, running_loss_seg / 10))\n",
    "                running_loss_seg = 0.0\n",
    "                \n",
    "            if step%50 == 49:\n",
    "                net.eval()\n",
    "                val_loss = 0\n",
    "                for batch in valid_loader:\n",
    "                    imgs,labels = batch\n",
    "\n",
    "                    labels = labels.to(device)\n",
    "                    images = imgs.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        pred = net(images)\n",
    "\n",
    "                    val_loss += DiceLoss(pred,labels)\n",
    "                print('[%d, %5d] validation loss: %.3f' %(epoch + 1, step + 1, val_loss / len(valid_loader)))\n",
    "                scheduler.step(val_loss)\n",
    "                net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "unet = UNet(init_features=64).to(device)\n",
    "root_dir = os.path.expanduser(\"~/projects/ma/data/phantomDataset/vessel_subset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1,    10] loss: 0.813\n",
      "\n",
      "[1,    20] loss: 0.698\n",
      "\n",
      "[2,    30] loss: 0.616\n",
      "\n",
      "[2,    40] loss: 0.524\n",
      "\n",
      "[3,    50] loss: 0.425\n",
      "[3,    50] validation loss: 0.381\n",
      "\n",
      "[3,    60] loss: 0.334\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train(unet,device,val_per=0.1,epochs=3,batch_size=2,resize_to=None)\n",
    "except KeyboardInterrupt:\n",
    "    sys.exit()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8c637c72b1aa34e7653879802d227d5e3685ef841dd468798b64a5834fafda6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
